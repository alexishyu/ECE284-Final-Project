{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tcP-I6IWqvb",
        "outputId": "c2672039-df3c-4feb-ffbd-6c39c45b60cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model...\n",
            "VGG_quant(\n",
            "  (features): Sequential(\n",
            "    (0): QuantConv2d(\n",
            "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): QuantConv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): QuantConv2d(\n",
            "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): QuantConv2d(\n",
            "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): QuantConv2d(\n",
            "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): QuantConv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): QuantConv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): QuantConv2d(\n",
            "      256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (25): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): QuantConv2d(\n",
            "      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (28): ReLU(inplace=True)\n",
            "    (29): QuantConv2d(\n",
            "      8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (31): ReLU(inplace=True)\n",
            "    (32): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (33): QuantConv2d(\n",
            "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (35): ReLU(inplace=True)\n",
            "    (36): QuantConv2d(\n",
            "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (38): ReLU(inplace=True)\n",
            "    (39): QuantConv2d(\n",
            "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (41): ReLU(inplace=True)\n",
            "    (42): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (43): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "  )\n",
            "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-3ad028434199>:63: DeprecationWarning: <class '__main__.weight_quantization.<locals>._pq'> should not be instantiated. Methods on autograd functionsare all static, so you should invoke them on the class itself. Instantiating an autograd function will raise an error in a future version of PyTorch.\n",
            "  return _pq().apply\n",
            "<ipython-input-10-3ad028434199>:109: DeprecationWarning: <class '__main__.act_quantization.<locals>._uq'> should not be instantiated. Methods on autograd functionsare all static, so you should invoke them on the class itself. Instantiating an autograd function will raise an error in a future version of PyTorch.\n",
            "  return _uq().apply\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "#from tensorboardX import SummaryWriter\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def weight_quantization(b):\n",
        "\n",
        "    def uniform_quant(x, b):\n",
        "        xdiv = x.mul((2 ** b - 1))\n",
        "        xhard = xdiv.round().div(2 ** b - 1)\n",
        "        #print('uniform quant bit: ', b)\n",
        "        return xhard\n",
        "\n",
        "    class _pq(torch.autograd.Function):\n",
        "        @staticmethod\n",
        "        def forward(ctx, input, alpha):\n",
        "            input.div_(alpha)                          # weights are first divided by alpha\n",
        "            input_c = input.clamp(min=-1, max=1)       # then clipped to [-1,1]\n",
        "            sign = input_c.sign()\n",
        "            input_abs = input_c.abs()\n",
        "            input_q = uniform_quant(input_abs, b).mul(sign)\n",
        "            ctx.save_for_backward(input, input_q)\n",
        "            input_q = input_q.mul(alpha)               # rescale to the original range\n",
        "            return input_q\n",
        "\n",
        "        @staticmethod\n",
        "        def backward(ctx, grad_output):\n",
        "            grad_input = grad_output.clone()             # grad for weights will not be clipped\n",
        "            input, input_q = ctx.saved_tensors\n",
        "            i = (input.abs()>1.).float()     # >1 means clipped. # output matrix is a form of [True, False, True, ...]\n",
        "            sign = input.sign()              # output matrix is a form of [+1, -1, -1, +1, ...]\n",
        "            #grad_alpha = (grad_output*(sign*i + (input_q-input)*(1-i))).sum()\n",
        "            grad_alpha = (grad_output*(sign*i + (0.0)*(1-i))).sum()\n",
        "            # above line, if i = True,  and sign = +1, \"grad_alpha = grad_output * 1\"\n",
        "            #             if i = False, \"grad_alpha = grad_output * (input_q-input)\"\n",
        "            grad_input = grad_input*(1-i)\n",
        "            return grad_input, grad_alpha\n",
        "\n",
        "    return _pq().apply\n",
        "\n",
        "\n",
        "class weight_quantize_fn(nn.Module):\n",
        "    def __init__(self, w_bit):\n",
        "        super(weight_quantize_fn, self).__init__()\n",
        "        self.w_bit = w_bit-1\n",
        "        self.weight_q = weight_quantization(b=self.w_bit)\n",
        "        self.register_parameter('wgt_alpha', Parameter(torch.tensor(3.0)))\n",
        "\n",
        "    def forward(self, weight):\n",
        "        mean = weight.data.mean()\n",
        "        std = weight.data.std()\n",
        "        weight = weight.add(-mean).div(std)      # weights normalization\n",
        "        weight_q = self.weight_q(weight, self.wgt_alpha)\n",
        "\n",
        "        return weight_q\n",
        "\n",
        "\n",
        "def act_quantization(b):\n",
        "\n",
        "    def uniform_quant(x, b=2):\n",
        "        xdiv = x.mul(2 ** b - 1)\n",
        "        xhard = xdiv.round().div(2 ** b - 1)\n",
        "        return xhard\n",
        "\n",
        "    class _uq(torch.autograd.Function):\n",
        "        @staticmethod\n",
        "        def forward(ctx, input, alpha):\n",
        "            input=input.div(alpha)\n",
        "            input_c = input.clamp(max=1)  # Mingu edited for Alexnet\n",
        "            input_q = uniform_quant(input_c, b)\n",
        "            ctx.save_for_backward(input, input_q)\n",
        "            input_q = input_q.mul(alpha)\n",
        "            return input_q\n",
        "\n",
        "        @staticmethod\n",
        "        def backward(ctx, grad_output):\n",
        "            grad_input = grad_output.clone()\n",
        "            input, input_q = ctx.saved_tensors\n",
        "            i = (input > 1.).float()\n",
        "            #grad_alpha = (grad_output * (i + (input_q - input) * (1 - i))).sum()\n",
        "            grad_alpha = (grad_output * (i + (0.0)*(1-i))).sum()\n",
        "            grad_input = grad_input*(1-i)\n",
        "            return grad_input, grad_alpha\n",
        "\n",
        "    return _uq().apply\n",
        "\n",
        "\n",
        "class QuantConv2d(nn.Conv2d):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n",
        "        super(QuantConv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups,\n",
        "                                          bias)\n",
        "        self.layer_type = 'QuantConv2d'\n",
        "        self.bit = 2\n",
        "        self.weight_quant = weight_quantize_fn(w_bit=self.bit)\n",
        "        self.act_alq = act_quantization(self.bit)\n",
        "        self.act_alpha = torch.nn.Parameter(torch.tensor(8.0))\n",
        "        self.weight_q  = torch.nn.Parameter(torch.zeros([out_channels, in_channels, kernel_size, kernel_size]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        weight_q = self.weight_quant(self.weight)\n",
        "        #self.register_parameter('weight_q', Parameter(weight_q))  # Mingu added\n",
        "        self.weight_q = torch.nn.Parameter(weight_q)  # Store weight_q during the training\n",
        "        x = self.act_alq(x, self.act_alpha)\n",
        "        return F.conv2d(x, weight_q, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "    def show_params(self):\n",
        "        wgt_alpha = round(self.weight_quant.wgt_alpha.data.item(), 3)\n",
        "        act_alpha = round(self.act_alpha.data.item(), 3)\n",
        "        print('clipping threshold weight alpha: {:2f}, activation alpha: {:2f}'.format(wgt_alpha, act_alpha))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16_quant': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 8, '8i', 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG16': ['F', 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "\n",
        "class VGG_quant(nn.Module):\n",
        "    def __init__(self, vgg_name):\n",
        "        super(VGG_quant, self).__init__()\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            elif x == 'F':  # This is for the 1st layer\n",
        "                layers += [nn.Conv2d(in_channels, 64, kernel_size=3, padding=1, bias=False),\n",
        "                           nn.BatchNorm2d(64),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = 64\n",
        "            elif x == '8i':\n",
        "                layers += [QuantConv2d(in_channels, 8, kernel_size=3, padding=1),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = 8\n",
        "            else:\n",
        "                layers += [QuantConv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def show_params(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, QuantConv2d):\n",
        "                m.show_params()\n",
        "\n",
        "\n",
        "def VGG16_quant(**kwargs):\n",
        "    model = VGG_quant(vgg_name = 'VGG16_quant', **kwargs)\n",
        "    return model\n",
        "\n",
        "global best_prec\n",
        "use_gpu = torch.cuda.is_available()\n",
        "print('=> Building model...')\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "model_name = \"VGG16_quant\"\n",
        "model = VGG16_quant()\n",
        "\n",
        "print(model)\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]))\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]))\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
        "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
        "\n",
        "def train(trainloader, model, criterion, optimizer, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(trainloader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        input, target = input.cuda(), target.cuda()\n",
        "\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec = accuracy(output, target)[0]\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(prec.item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
        "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
        "                   data_time=data_time, loss=losses, top1=top1))\n",
        "\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion ):\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "\n",
        "            input, target = input.cuda(), target.cuda()\n",
        "\n",
        "            # compute output\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            prec = accuracy(output, target)[0]\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(prec.item(), input.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
        "                print('Test: [{0}/{1}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
        "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                   top1=top1))\n",
        "\n",
        "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
        "    return top1.avg\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, fdir):\n",
        "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
        "    torch.save(state, filepath)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
        "    adjust_list = [20, 50]\n",
        "    if epoch in adjust_list:\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = param_group['lr'] * 0.1\n",
        "\n",
        "lr = 0.01\n",
        "weight_decay = 1e-3\n",
        "epochs = 80\n",
        "best_prec = 0\n",
        "\n",
        "#model = nn.DataParallel(model).cuda()\n",
        "model.cuda()\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "cudnn.benchmark = True\n",
        "if not os.path.exists('result'):\n",
        "    os.makedirs('result')\n",
        "fdir = 'result/'+str(model_name)\n",
        "if not os.path.exists(fdir):\n",
        "    os.makedirs(fdir)\n",
        "\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "    train(trainloader, model, criterion, optimizer, epoch)\n",
        "\n",
        "    # evaluate on test set\n",
        "    print(\"Validation starts\")\n",
        "    prec = validate(testloader, model, criterion)\n",
        "    #scheduler.step(prec)\n",
        "\n",
        "    # remember best precision and save checkpoint\n",
        "    is_best = prec > best_prec\n",
        "    best_prec = max(prec,best_prec)\n",
        "    print('best acc: {:1f}'.format(best_prec))\n",
        "    save_checkpoint({\n",
        "        'epoch': epoch + 1,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'best_prec': best_prec,\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "    }, is_best, fdir)"
      ],
      "metadata": {
        "id": "bCOf-w3nXcUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"result/VGG16_quant/model_best.pth.tar\"\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model.cuda()\n",
        "model.eval()\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in testloader:\n",
        "        data, target = data.to(device), target.to(device) # loading to GPU\n",
        "        output = model(data)\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(testloader.dataset)\n",
        "\n",
        "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        correct, len(testloader.dataset),\n",
        "        100. * correct / len(testloader.dataset)))"
      ],
      "metadata": {
        "id": "ARmJT1UWXfYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveOutput:\n",
        "    def __init__(self):\n",
        "        self.outputs = []\n",
        "    def __call__(self, module, module_in):\n",
        "        self.outputs.append(module_in)\n",
        "    def clear(self):\n",
        "        self.outputs = []\n",
        "\n",
        "######### Save inputs from selected layer ##########\n",
        "save_output = SaveOutput()\n",
        "i = 0\n",
        "\n",
        "for layer in model.modules():\n",
        "    i = i+1\n",
        "    if isinstance(layer, QuantConv2d):\n",
        "        print(i,\"-th layer prehooked\")\n",
        "        layer.register_forward_pre_hook(save_output)\n",
        "####################################################\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.to(device)\n",
        "out = model(images)"
      ],
      "metadata": {
        "id": "P1hLs9mYXiUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_q = model.features[27].weight_q\n",
        "w_alpha = model.features[27].weight_quant.wgt_alpha\n",
        "w_bit = 4\n",
        "\n",
        "weight_int = weight_q / (w_alpha / (2**(w_bit-1)-1))\n",
        "print(weight_int)"
      ],
      "metadata": {
        "id": "PvOOloayX0d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act = save_output.outputs[8][0]\n",
        "act_alpha  = model.features[27].act_alpha\n",
        "act_bit = 4\n",
        "act_quant_fn = act_quantization(act_bit)\n",
        "\n",
        "act_q = act_quant_fn(act, act_alpha)\n",
        "\n",
        "act_int = act_q / (act_alpha / (2**act_bit-1))\n",
        "print(act_int)"
      ],
      "metadata": {
        "id": "9_7-ESUoX36v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_int = torch.nn.Conv2d(in_channels = 64, out_channels=64, kernel_size = 3, padding=1)\n",
        "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
        "conv_int.bias = model.features[3].bias\n",
        "output_int = conv_int(act_int)\n",
        "output_recovered = output_int * (act_alpha / (2**act_bit-1)) * (w_alpha / (2**(w_bit-1)-1))\n",
        "print(output_recovered)"
      ],
      "metadata": {
        "id": "7E3RsuwgX6Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_output.clear()\n",
        "model.features[28].register_forward_pre_hook(save_output)\n",
        "sample_data, _ = next(iter(testloader))  # Get a batch of test data\n",
        "sample_data = sample_data.cuda()\n",
        "model(sample_data)\n",
        "\n",
        "hooked_output = save_output.outputs[0][0]\n",
        "print(hooked_output.size())"
      ],
      "metadata": {
        "id": "sjIKrBsgX8rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(output_recovered.size())\n",
        "output_recovered_reduced = output_recovered.mean(dim=1, keepdim=True)\n",
        "difference = torch.abs(hooked_output - output_recovered_reduced)\n",
        "print(\"Difference:\", difference.mean())"
      ],
      "metadata": {
        "id": "-2aZ1LIKX-mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### show this cell partially. The following cells should be printed by students ###\n",
        "tile_id = 0\n",
        "nij = 200 # just a random number\n",
        "X = a_tile[tile_id,:,nij:nij+64]  # [tile_num, array row num, time_steps]\n",
        "\n",
        "bit_precision = 4\n",
        "file = open('activation.txt', 'w') #write to file\n",
        "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
        "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
        "file.write('#................#\\n')\n",
        "\n",
        "for i in range(X.size(1)):  # time step\n",
        "    for j in range(X.size(0)): # row #\n",
        "        X_bin = '{0:04b}'.format(round(X[7-j,i].item()))\n",
        "        for k in range(bit_precision):\n",
        "            file.write(X_bin[k])\n",
        "        #file.write(' ')  # for visibility with blank between words, you can use\n",
        "    file.write('\\n')\n",
        "file.close() #close file\n"
      ],
      "metadata": {
        "id": "4Y5uADmJYA7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Complete this cell ###\n",
        "tile_id = 0\n",
        "kij = 0\n",
        "W = w_tile[tile_id,:,:,kij]  # w_tile[tile_num, array col num, array row num, kij]\n",
        "\n",
        "\n",
        "bit_precision = 4\n",
        "file = open('weight0.txt', 'w') #write to file\n",
        "file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
        "file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
        "file.write('#................#\\n')\n",
        "\n",
        "for i in range(W.size(0)):  # column number\n",
        "    for j in range(W.size(1)):  # row number\n",
        "        # Convert to 2's complement for negative numbers\n",
        "        val = round(W[i,7-j].item())\n",
        "        if val < 0:\n",
        "            val = val + 2**bit_precision  # Convert negative to 2's complement\n",
        "        W_bin = '{0:04b}'.format(val)\n",
        "        for k in range(bit_precision):\n",
        "            file.write(W_bin[k])\n",
        "    file.write('\\n')\n",
        "file.close()"
      ],
      "metadata": {
        "id": "rHV-e2EMYCud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Complete this cell ###\n",
        "ic_tile_id = 0\n",
        "oc_tile_id = 0\n",
        "\n",
        "\n",
        "kij = 0\n",
        "nij = 200\n",
        "psum_tile = psum[ic_tile_id,oc_tile_id,:,nij:nij+64,kij]\n",
        "# psum[len(ic_tileg), len(oc_tileg), array_size, len(p_nijg), len(kijg)]\n",
        "\n",
        "\n",
        "bit_precision = 16\n",
        "file = open('psum.txt', 'w') #write to file\n",
        "file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
        "file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
        "file.write('#................#\\n')\n",
        "\n",
        "for i in range(psum_tile.size(1)):  # time steps\n",
        "    for j in range(psum_tile.size(0)):  # column number\n",
        "        # Convert to 2's complement for negative numbers\n",
        "        val = round(psum_tile[7-j,i].item())\n",
        "        if val < 0:\n",
        "            val = val + 2**bit_precision  # Convert negative to 2's complement\n",
        "        psum_bin = '{0:016b}'.format(val)\n",
        "        for k in range(bit_precision):\n",
        "            file.write(psum_bin[k])\n",
        "    file.write('\\n')\n",
        "file.close()"
      ],
      "metadata": {
        "id": "9Sl5dSsnYEX4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}